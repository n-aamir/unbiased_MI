{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_MI(spike_train, stimulus_trace):\n",
    "\n",
    "    \"\"\" \n",
    "    Computes the naive mutual information of a population of cells\n",
    "\n",
    "    Arguments\n",
    "    ----------\n",
    "    spike_train (np.ndarray) :    spike count of a neuron (N) in a time bin (T) - size (T * N)  \n",
    "    stimulus_trace (np.array):   state/position at T    \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    MI (np.array):       naive mutual information for each neuron (N)\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    #set constant to prevent numerical issues\n",
    "    epsilon = 1e-30 if spike_train.dtype == np.float32 or stimulus_trace.dtype == np.float32 else np.finfo(float).tiny\n",
    "    \n",
    "    #getting unique states and count occurrences\n",
    "    states = np.unique(stimulus_trace)\n",
    "    num_states = len(states)\n",
    "    num_cells = spike_train.shape[0]\n",
    "    \n",
    "    #converting to integers if spike_train data has non-integer spike counts\n",
    "    if np.any(spike_train % 1 != 0):\n",
    "        spike_train = np.round(spike_train).astype(int)\n",
    "\n",
    "    #getting response bins\n",
    "    max_rate = np.max(spike_train)\n",
    "    response_bins = np.arange(max_rate + 1)\n",
    "   \n",
    "    #calculating the prior distribution of the encoded variable\n",
    "    p_s = np.array([np.sum(stimulus_trace == state) / len(stimulus_trace) for state in states])\n",
    "\n",
    "    #calculating marginal probabilities for responses\n",
    "    p_r = np.zeros((num_cells, len(response_bins)), order = 'F')\n",
    "\n",
    "    for r in range(len(response_bins)):\n",
    "        p_r[:, r] = np.sum(spike_train == response_bins[r], axis=1) / spike_train.shape[1]\n",
    "\n",
    "    #calculating conditional probability\n",
    "    p_r_given_s = np.zeros((num_cells, len(response_bins), num_states),order = 'F')\n",
    "\n",
    "    for s in range(num_states):\n",
    "        for r in range(len(response_bins)):\n",
    "            state_indices = np.where(stimulus_trace == states[s])[0]\n",
    "\n",
    "            if len(state_indices) > 1:\n",
    "                state_spike_train = spike_train[:, state_indices]\n",
    "                matches = state_spike_train == response_bins[r]\n",
    "                p_r_given_s[:, r, s] = np.sum(matches, axis=1) / len(state_indices)\n",
    "            else:\n",
    "                matches = (spike_train[:, state_indices] == response_bins[r]).astype(int)\n",
    "                p_r_given_s[:, r, s] = np.squeeze(matches)\n",
    "\n",
    "    #calculating conditional entropy\n",
    "    conditional_entropy = -np.sum(p_s * np.sum(p_r_given_s * np.log2(p_r_given_s + epsilon), axis=1), axis=1)\n",
    "\n",
    "    #calculating response entropy\n",
    "    response_entropy = -np.sum(p_r * np.log2(p_r + epsilon), axis=1)\n",
    "    \n",
    "    #calculating Mutual Information (MI)\n",
    "    MI = response_entropy - conditional_entropy\n",
    "    MI[np.isnan(MI)] = 0  #handling cases with NaN results\n",
    "    \n",
    "    return MI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_SI(average_firing_rates, tuning_curves, stimulus_distribution):\n",
    "\n",
    "    \"\"\" \n",
    "    Computes the naive Skaggs information index (SI) of a population of cells\n",
    "\n",
    "    Arguments\n",
    "    ----------\n",
    "    average_firing_rates (np.array) :    \n",
    "    tuning_curves (np.array):      \n",
    "    stimulus_distribution (np.array): \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    SI_bit_spike (np.array)  \n",
    "    SI_bit_sec (np.array)   \n",
    "    \"\"\"\n",
    "\n",
    "    #set constant to prevent numerical issues\n",
    "    epsilon = 1e-30 if any(arr.dtype == np.float32 for arr in (average_firing_rates, tuning_curves, stimulus_distribution)) else np.finfo(float).tiny\n",
    "\n",
    "    #normalizing tuning curves\n",
    "    norm_tuning_curves = tuning_curves / (average_firing_rates[:, np.newaxis] + epsilon)\n",
    "\n",
    "    #calculating SI in bits per spike\n",
    "    SI_bit_spike = np.nansum(stimulus_distribution * norm_tuning_curves * np.log2(norm_tuning_curves + epsilon), axis=1)\n",
    "    SI_bit_spike[average_firing_rates == 0] = np.nan\n",
    "    \n",
    "    #calculating SI in bits per sec\n",
    "    SI_bit_sec = SI_bit_spike * average_firing_rates\n",
    "    SI_bit_sec[np.isnan(SI_bit_spike)] = 0\n",
    "\n",
    "    return SI_bit_spike, SI_bit_sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_spike_trains(spike_train, num_shuffles, shuffle_type):\n",
    "    \"\"\"\n",
    "    Performs either a cyclic permutation or random shuffling to obtain shuffled spike trains\n",
    "    \n",
    "    Arguments\n",
    "    ----------\n",
    "    spike_train (np.array)\n",
    "    num_shuffles (int): Number of shuffling repetitions\n",
    "    shuffle_type (string) Either 'cyclic' or 'random' permutations\n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "    shuffled_spike_trains (tensor):  shape (N, T, K), where N is the number of neurons, T is the number of time bins, \n",
    "       and K is the number of shuffles. Each element is the spike count of a given neuron in a given time bin.\n",
    "    \"\"\"\n",
    "    \n",
    "    N,T = spike_train.shape\n",
    "    shuffled_spike_trains = np.zeros((N, T, num_shuffles), order = 'F', dtype=spike_train.dtype)\n",
    "\n",
    "    if shuffle_type == 'cyclic':\n",
    "        for n in range(num_shuffles):\n",
    "            shift_index = np.random.randint(T)  #randomly selecting a shift index\n",
    "            shuffled_spike_trains[:, :, n] = np.roll(spike_train, shift_index, axis=0)  #performing cyclic permutation\n",
    "    elif shuffle_type == 'random':\n",
    "        for n in range(num_shuffles):\n",
    "            random_indexes = np.argsort(np.random.rand(T))  #generating random indexes\n",
    "            shuffled_spike_trains[:, :, n] = spike_train[:, random_indexes]  #random shuffling the spike train\n",
    "    else:\n",
    "        raise ValueError('Please choose a valid shuffling type')\n",
    "    \n",
    "\n",
    "    return shuffled_spike_trains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tuning_curves(spike_train, stimulus_trace, dt):\n",
    "\n",
    "    \"\"\"\n",
    "    Computes tuning curves\n",
    "    \n",
    "    Arguments\n",
    "    ----------\n",
    "    spike_train (np.array)\n",
    "    stimulus_trace (np.array)\n",
    "    dt (float): Temporal bin size (in seconds)\n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "    tuning_curves (np.ndarray): firing rate map of each neuron at each position/stmuli\n",
    "    stimulus_distribution (np.array): array of size S with probabilities of the each stimuli\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    #calculating stimulus distribution\n",
    "    stimulus_values, stimulus_counts = np.unique(stimulus_trace, return_counts=True)\n",
    "    stimulus_distribution = stimulus_counts / len(stimulus_trace)\n",
    "\n",
    "    #determining the number of stimulus values, neurons, and time bins\n",
    "    num_stimulus_values = len(stimulus_values)\n",
    "    num_cells = spike_train.shape[0]\n",
    "\n",
    "    #intilaizing tuning_curves\n",
    "    tuning_curves = np.zeros((num_cells, num_stimulus_values), order = 'F')\n",
    "\n",
    "    for n in range(num_stimulus_values):\n",
    "        this_bin_indexes = np.where(stimulus_trace == stimulus_values[n])[0]\n",
    "\n",
    "        if len(this_bin_indexes) > 1:\n",
    "            #calculating the mean firing rate within the time bin\n",
    "            tuning_curves[:, n] = np.mean(spike_train[:, this_bin_indexes], axis=1) / dt\n",
    "        else:\n",
    "            #using the firing rate directly if only one time bin\n",
    "            tuning_curves[:, n] = spike_train[:, this_bin_indexes].flatten() / dt\n",
    "\n",
    "    return tuning_curves, stimulus_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_info_versus_sample_size(spike_train, stimulus_trace, sample_sizes, dt, repetitions, info_measures):\n",
    "\n",
    "    \"\"\"\n",
    "    Computes information content using multiple sample sizes\n",
    "    \n",
    "    Arguments\n",
    "    ----------\n",
    "    spike_train (np.array)\n",
    "    stimulus_trace (np.array)\n",
    "    sample_sizes (np.array): array of sample sizes\n",
    "    dt (float): Temporal bin size (in seconds)\n",
    "    repetitions (int): number of repititions for each sample size\n",
    "    info_measures (np.array): binary array to indicate measures to compute (size 1*3)\n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    results (np.ndarray): information content\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    N,T = spike_train.shape\n",
    "    sample_sizes = sample_fraction*T\n",
    "    nbr_samples = len(sample_sizes)\n",
    "   \n",
    "    #initializing arrays to store information content\n",
    "    if info_measures[0] or info_measures[1]:\n",
    "        info_bit_spike_vs_sample = np.full((N, nbr_samples), np.nan, order = 'F')\n",
    "        shuffle_info_bit_spike_vs_sample = np.full((N, nbr_samples), np.nan, order = 'F')\n",
    "        info_bit_sec_vs_sample = np.full((N, nbr_samples), np.nan, order = 'F')\n",
    "        shuffle_info_bit_sec_vs_sample = np.full((N, nbr_samples), np.nan, order = 'F')\n",
    "\n",
    "    if info_measures[2]:\n",
    "        info_mi_vs_sample = np.full((N,nbr_samples), np.nan, order = 'F')\n",
    "        shuffle_info_mi_vs_sample = np.full((N, nbr_samples), np.nan, order = 'F')\n",
    "\n",
    "    #calculating info for different sample sizes\n",
    "    for n in range(nbr_samples):\n",
    "\n",
    "        col_dim = int(np.ceil(repetitions * T / sample_sizes[n]))\n",
    "\n",
    "        num_time_bins = int(np.floor(sample_sizes[n]))\n",
    "\n",
    "        if info_measures[0] or info_measures[1]:\n",
    "            #initializing arrays to store information content\n",
    "            info_bit_spike = np.full((N, col_dim), np.nan, order = 'F')\n",
    "            shuffle_info_bit_spike = np.full((N, col_dim), np.nan, order = 'F')\n",
    "            info_bit_sec = np.full((N, col_dim), np.nan, order = 'F')\n",
    "            shuffle_info_bit_sec = np.full((N, col_dim), np.nan, order = 'F')\n",
    "        \n",
    "        if info_measures[2]:\n",
    "            #initializing arrays to store information content\n",
    "            info_mi = np.full((N, col_dim), np.nan, order = 'F')\n",
    "            shuffle_info_mi = np.full((N, col_dim), np.nan, order = 'F')\n",
    "     \n",
    "        for k in range(col_dim):\n",
    "            #shuffling spike trains\n",
    "            sample_indexes = np.argsort(np.random.rand(T))[:num_time_bins]\n",
    "            shuffled_spikes =np.squeeze( shuffle_spike_trains(spike_train[:, sample_indexes], 1, 'cyclic'))\n",
    "            \n",
    "            if info_measures[0] or info_measures[1]:\n",
    "\n",
    "                #computing tunung curves and calculating information content\n",
    "                temp_tc, temp_states_distribution = compute_tuning_curves(spike_train[:, sample_indexes], stimulus_trace[sample_indexes], dt)\n",
    "                temp_fr = np.mean(spike_train[:, sample_indexes], axis=1) / dt\n",
    "\n",
    "                \n",
    "                temp_info_bit_spike, temp_info_bit_sec = compute_SI(temp_fr, temp_tc, temp_states_distribution)\n",
    "\n",
    "                info_bit_spike[:, k] = temp_info_bit_spike\n",
    "                info_bit_sec[:, k] = temp_info_bit_sec\n",
    "\n",
    "                temp_shuffled_tc, _ = compute_tuning_curves(shuffled_spikes, stimulus_trace[sample_indexes], dt)\n",
    "                temp_shuffle_fr = np.mean(shuffled_spikes, axis=1) / dt\n",
    "                temp_shuffle_info_bit_spike, temp_shuffle_info_bit_sec = compute_SI(temp_shuffle_fr, temp_shuffled_tc, temp_states_distribution)\n",
    "                shuffle_info_bit_spike[:, k] = temp_shuffle_info_bit_spike\n",
    "                shuffle_info_bit_sec[:, k] = temp_shuffle_info_bit_sec\n",
    "             \n",
    "            if info_measures[2]:\n",
    "                temp_mi = compute_MI(spike_train[:, sample_indexes], stimulus_trace[sample_indexes])\n",
    "                info_mi[:, k] = temp_mi\n",
    "                    \n",
    "                temp_mi_shuffle = compute_MI(shuffled_spikes, stimulus_trace[sample_indexes])\n",
    "                shuffle_info_mi[:, k] = temp_mi_shuffle\n",
    "\n",
    "        if info_measures[0] or info_measures[1]:\n",
    "            #averaging info content across sample sizes\n",
    "            info_bit_spike_vs_sample[:, n] = np.nanmean(info_bit_spike, axis=1)\n",
    "            shuffle_info_bit_spike_vs_sample[:, n] = np.nanmean(shuffle_info_bit_spike, axis=1)\n",
    "            info_bit_sec_vs_sample[:, n] = np.nanmean(info_bit_sec, axis=1)\n",
    "            shuffle_info_bit_sec_vs_sample[:, n] = np.nanmean(shuffle_info_bit_sec, axis=1)\n",
    " \n",
    "        if info_measures[2]:\n",
    "            info_mi_vs_sample[:, n] = np.nanmean(info_mi, axis=1)\n",
    "            shuffle_info_mi_vs_sample[:, n] = np.nanmean(shuffle_info_mi, axis=1)\n",
    "                \n",
    "    results = []\n",
    "    if info_measures[0] or info_measures[1]:\n",
    "        results.extend([info_bit_spike_vs_sample, shuffle_info_bit_spike_vs_sample, info_bit_sec_vs_sample, shuffle_info_bit_sec_vs_sample])\n",
    "    if info_measures[2]:\n",
    "        results.extend([info_mi_vs_sample, shuffle_info_mi_vs_sample])\n",
    "\n",
    "    return results       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### function to shuffle spike trains according to Gansel, 2012\n",
    "###\n",
    "### inputs:\n",
    "###         mode  - specify mode for shuffling\n",
    "###               'shift'       - shift spike train by a fixed offset (default)\n",
    "###                       provide values as (mode,shuffle_peaks,spike_train)\n",
    "###               'dither'      - dither each spike by an independently drawn random value (max = w)\n",
    "###                       provide values as (mode,shuffle_peaks,spike_times,spikes,T,ISI,w,shuffle_spikes)\n",
    "###               'dithershift' - combination of 'shift' and 'dither' method\n",
    "###                       provide values as (mode,shuffle_peaks,spike_times,spikes,T,ISI,w,shuffle_spikes)\n",
    "###               'dsr'         - (dither-shift-reorder), same as 'dithershift' but with random reordering of consecutive ISIs < w (?)\n",
    "###                       provide values as (mode,shuffle_peaks,spike_times,spikes,T,ISI,w,shuffle_spikes)\n",
    "###\n",
    "###         shuffle_peaks  - boolean: should assignment \"spikes\" to \"spike_times\" be shuffled?\n",
    "###\n",
    "###         spike_train - spike train as binary array (should be replaced by ISI & T\n",
    "###\n",
    "###         spike_times - frames at which spikes happen\n",
    "###\n",
    "###         spikes      - number of spikes happening at times \"spike_times\"\n",
    "###\n",
    "###         T     - length of the overall recording (= maximum value for new spike time)\n",
    "###\n",
    "###         ISI   - InterSpike Intervalls of the spike train\n",
    "###\n",
    "###         w     - maximum dithering (~1/(2*rate)?)\n",
    "###\n",
    "### ouputs:\n",
    "###         new_spike_train - shuffled spike train\n",
    "###\n",
    "###   written by A.Schmidt, last reviewed on January, 22nd, 2020\n",
    "\n",
    "\n",
    "#from numba import jit\n",
    "\n",
    "#@jit\n",
    "def shuffling(mode,shuffle_peaks,**varin):\n",
    "  \n",
    "  if mode == 'shift':\n",
    "    \n",
    "    [new_spike_train,tmp] = shift_spikes(varin['spike_train'])\n",
    "    if shuffle_peaks:\n",
    "      spike_times = np.where(new_spike_train)[0]\n",
    "      spikes = new_spike_train[spike_times]\n",
    "      new_spike_train[spike_times] = spikes[np.random.permutation(len(spike_times))]        ## shuffle spike numbers\n",
    "    \n",
    "  elif mode == 'dither':\n",
    "    \n",
    "    assert len(args)>=2, \"You did not provide enough input. Please check the function description for further information.\"\n",
    "    [spike_times,spikes,T,ISI,w] = get_input_dither(varin);\n",
    "    \n",
    "    new_spike_train = dither_spikes(spike_times,spikes,T,ISI,w,shuffle_peaks);\n",
    "    \n",
    "  elif mode == 'dithershift':\n",
    "    \n",
    "    assert len(args)>=4, \"You did not provide enough input. Please check the function description for further information.\"\n",
    "    [spike_times,spikes,T,ISI,w] = get_input_dither(varin);\n",
    "    \n",
    "    new_spike_train = dither_spikes(spike_times,spikes,T,ISI,w,shuffle_peaks);\n",
    "    [new_spike_train,shift] = shift_spikes(new_spike_train);\n",
    "    \n",
    "  elif mode == 'dsr':\n",
    "  \n",
    "    print('not yet implemented')\n",
    "    new_spike_train = np.NaN;\n",
    "    \n",
    "  \n",
    "  #plt = false;\n",
    "  #if plt && strcmp(mode,'dithershift')\n",
    "    \n",
    "    #if ~exist('spike_train','var')\n",
    "      #spike_train = zeros(1,T);\n",
    "      #spike_train(spike_times) = spikes;\n",
    "    #end\n",
    "    #ISI = get_ISI(spike_train);\n",
    "    #newISI = get_ISI(new_spike_train);\n",
    "    \n",
    "    #figure('position',[500 500 1200 900])\n",
    "    #subplot(3,1,1)\n",
    "    #plot(spike_train)\n",
    "    #subplot(3,1,2)\n",
    "    #plot(new_spike_train)\n",
    "    #title('new spike train')\n",
    "    \n",
    "    #subplot(3,2,5)\n",
    "    #hold on\n",
    "    #histogram(log10(ISI),linspace(-2,2,51),'FaceColor','b')\n",
    "    #histogram(log10(newISI),linspace(-2,2,51),'FaceColor','r')\n",
    "    #hold off\n",
    "    \n",
    "    #waitforbuttonpress;\n",
    "  #end\n",
    "  return new_spike_train\n",
    "\n",
    "\n",
    "\n",
    "def shift_spikes(spike_train):\n",
    "  \n",
    "  shift = np.random.randint(np.max([1,len(spike_train)]))\n",
    "  new_spike_train = np.concatenate([spike_train[shift:],spike_train[:shift]])    ## shift spike train\n",
    "  return new_spike_train,shift\n",
    "\n",
    "\n",
    "def get_input_dither(argin):\n",
    "  \n",
    "  if len(argin['w']) == 1:\n",
    "    spike_train = argin['spike_train']\n",
    "    spike_times = np.where(spike_train)[0]\n",
    "    spikes = spike_train[spike_times]\n",
    "    T = len(spike_train)\n",
    "    ISI = np.diff(spike_times)\n",
    "    \n",
    "  else:\n",
    "    spike_times = argin['spike_times']\n",
    "    spikes = argin['spikes']\n",
    "    T = argin['T']\n",
    "    ISI = argin['ISI']\n",
    "    \n",
    "  return spike_times,spikes,T,ISI,argin['w']\n",
    "\n",
    "\n",
    "def dither_spikes(spike_times,spikes,T,ISI,w,shuffle_peaks):\n",
    "  \n",
    "  nspike_times = len(spike_times);\n",
    "  \n",
    "  dither = np.min([ISI-1,2*w])/2;\n",
    "  \n",
    "  r = 2*(rand(1,len(ISI)-1)-0.5);\n",
    "  \n",
    "  for i in range(1,len(ISI)):   ## probability of being left or right of initial spike should be equal! (otherwise, it destroys bursts!)\n",
    "    print('i: %d',i)\n",
    "    spike_times[i] = spike_times[i] + min(0,r[i-1])*ISI[i-1] + max(0,r[i-1])*ISI[i];\n",
    "  \n",
    "  spike_times = round(spike_times)\n",
    "  \n",
    "  if shuffle_peaks:\n",
    "    print(nspike_times)\n",
    "    print(nspike_times.shape)\n",
    "    print('watch out: permutation only works along first dimension ... proper shape?')\n",
    "    spikes = spikes[np.random.permutation(nspike_times)]\n",
    "  \n",
    "  new_spike_train = np.zeros(T)\n",
    "  for i in range(nspike_times):\n",
    "    t = spike_times[i]\n",
    "    new_spike_train[t] = new_spike_train[t] + spikes[i]\n",
    "  \n",
    "  return new_spike_train\n",
    "\n",
    "\n",
    "\n",
    "def get_ISI(spike_train):\n",
    "  \n",
    "  ## this part effectively splits up spike bursts (single event with multiple spikes to multiple events with single spikes)\n",
    "  spike_times = np.where(spike_train)[0];\n",
    "  idx_old = 1;\n",
    "  new_spike_times = [];\n",
    "  # print(np.where(spike_train>1))\n",
    "  # print(np.where(spike_train>1)[0])\n",
    "  for t in np.where(spike_train>1)[0]:\n",
    "    idx_new = np.where(spike_times==t)[0]\n",
    "    nspikes = spike_train[t]\n",
    "    \n",
    "    new_spike_times = np.append([new_spike_times,spike_times[idx_old:idx_new],t+np.linspace(0,1-1/nspikes,nspikes)]);\n",
    "    #idx_old = idx_new+1;\n",
    "  \n",
    "  new_spike_times = np.append([new_spike_times,spike_times[idx_old:]]);\n",
    "  return np.diff(new_spike_times);\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "caiman",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
